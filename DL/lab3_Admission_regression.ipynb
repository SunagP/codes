{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EgiKfwVqDZjX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oT_Fu9jiDr64"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Predict_Ver.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c1YTCsooD4Nb",
    "outputId": "a58ee380-199b-46c2-bfac-b7accf071875"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Dqmw9W4sGopf"
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lT_2UWZfG9Wv"
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scalar=StandardScaler()\n",
    "\n",
    "# x_tranin_trf=scalar.fit_transform(x_train)\n",
    "# x_test_trf=scalar.transform(x_test)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar=MinMaxScaler()\n",
    "\n",
    "x_tranin_trf=scalar.fit_transform(x_train)\n",
    "x_test_trf=scalar.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "IHyayYPWHWKK"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uk-0bdEZIjpI",
    "outputId": "ff9d1a05-42cb-4129-ec81-10814cb482f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tensorflow.keras.Sequential()\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpSaldb0KHt2",
    "outputId": "f1f80d6b-7cfb-45a7-a69c-964e522829b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 663us/step - loss: 0.3939\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 665us/step - loss: 0.0299\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 659us/step - loss: 0.0182\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.0145\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.0122\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 625us/step - loss: 0.0093\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 595us/step - loss: 0.0081\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 606us/step - loss: 0.0068\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.0060\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 603us/step - loss: 0.0055\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.0053\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.0053\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.0048\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.0046\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.0045\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 632us/step - loss: 0.0044\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 598us/step - loss: 0.0043\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 602us/step - loss: 0.0040\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 586us/step - loss: 0.0041\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.0040\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 677us/step - loss: 0.0040\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 669us/step - loss: 0.0039\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 683us/step - loss: 0.0040\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.0038\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 630us/step - loss: 0.0038\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.0038\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 582us/step - loss: 0.0037\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 630us/step - loss: 0.0037\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.0037\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 586us/step - loss: 0.0038\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 606us/step - loss: 0.0037\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 595us/step - loss: 0.0037\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.0036\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.0037\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 665us/step - loss: 0.0037\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 605us/step - loss: 0.0037\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 621us/step - loss: 0.0037\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 676us/step - loss: 0.0036\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 596us/step - loss: 0.0036\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 612us/step - loss: 0.0037\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 577us/step - loss: 0.0036\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 591us/step - loss: 0.0036\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.0036\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 596us/step - loss: 0.0037\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 622us/step - loss: 0.0036\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 623us/step - loss: 0.0035\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 615us/step - loss: 0.0038\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.0035\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 615us/step - loss: 0.0036\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 599us/step - loss: 0.0035\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 603us/step - loss: 0.0035\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.0035\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 597us/step - loss: 0.0035\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.0037\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.0035\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.0035\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 579us/step - loss: 0.0035\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 591us/step - loss: 0.0035\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 571us/step - loss: 0.0035\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.0034\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 590us/step - loss: 0.0034\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 592us/step - loss: 0.0036\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.0034\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.0036\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 561us/step - loss: 0.0035\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 557us/step - loss: 0.0034\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 590us/step - loss: 0.0035\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 592us/step - loss: 0.0035\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 612us/step - loss: 0.0036\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 586us/step - loss: 0.0034\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 557us/step - loss: 0.0037\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.0035\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.0034\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 583us/step - loss: 0.0034\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 595us/step - loss: 0.0034\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 595us/step - loss: 0.0035\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.0036\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.0034\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 582us/step - loss: 0.0034\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 569us/step - loss: 0.0034\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.0033\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 557us/step - loss: 0.0035\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.0034\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.0035\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.0034\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 569us/step - loss: 0.0034\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 569us/step - loss: 0.0034\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 584us/step - loss: 0.0036\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 559us/step - loss: 0.0034\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.0034\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 591us/step - loss: 0.0034\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 582us/step - loss: 0.0034\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 595us/step - loss: 0.0034\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.0033\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 557us/step - loss: 0.0035\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 586us/step - loss: 0.0034\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 583us/step - loss: 0.0035\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 589us/step - loss: 0.0034\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 586us/step - loss: 0.0036\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 572us/step - loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss=\"mean_squared_error\")\n",
    "history=model.fit(x_tranin_trf,y_train,epochs=100,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UraOpGqJW3B",
    "outputId": "44dc5f6d-0081-430d-91c0-c69f4668106a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'dense_9/kernel:0' shape=(7, 7) dtype=float32, numpy=\n",
      "array([[ 0.537271  , -0.31758496,  0.5801898 , -0.02792808,  0.2515317 ,\n",
      "        -0.26754948,  0.2950402 ],\n",
      "       [ 0.52814335, -0.2830664 ,  0.70943624, -0.30076727, -0.4703935 ,\n",
      "         0.28758213, -0.3041905 ],\n",
      "       [-0.2791964 ,  0.19734524,  0.67343163, -0.30189684,  0.12975322,\n",
      "        -0.47676763, -0.03666298],\n",
      "       [-0.04039048,  0.4400255 ,  0.73650557, -0.43771788, -0.6709276 ,\n",
      "         0.15053822,  0.24207816],\n",
      "       [-0.28944966, -0.279054  ,  0.13799663,  0.3507581 , -0.42386487,\n",
      "        -0.43731332, -0.11586371],\n",
      "       [ 0.18414594,  0.46975777,  0.13602607,  0.5603463 ,  0.19478069,\n",
      "        -0.22913966,  0.204746  ],\n",
      "       [-0.15407342,  0.19950435,  1.17235   , -0.10673098, -1.1074456 ,\n",
      "        -0.52531165,  0.7831939 ]], dtype=float32)>, <tf.Variable 'dense_9/bias:0' shape=(7,) dtype=float32, numpy=\n",
      "array([ 0.3843128 ,  0.126566  , -0.01999614,  0.27413002,  0.06829724,\n",
      "        0.00721261, -0.24488318], dtype=float32)>]\n",
      "[<tf.Variable 'dense_10/kernel:0' shape=(7, 7) dtype=float32, numpy=\n",
      "array([[ 0.50279087, -0.31267193, -0.6329387 , -0.5454559 ,  0.4112008 ,\n",
      "        -0.47946742,  0.33934796],\n",
      "       [ 0.25106293,  0.4998199 , -0.11979693, -0.6122156 , -0.36287358,\n",
      "         0.2712262 ,  0.2771311 ],\n",
      "       [ 0.06593584, -0.3375594 , -0.12108915,  0.24105576, -0.3484329 ,\n",
      "         0.4107091 ,  0.44657335],\n",
      "       [ 0.4464828 ,  0.09378917, -0.36617225,  0.43872645,  0.28723407,\n",
      "         0.36002374,  0.6137252 ],\n",
      "       [-0.26324856,  0.20691605,  0.3583003 , -0.3014546 ,  0.07314806,\n",
      "        -0.57166576, -0.36933914],\n",
      "       [ 0.22944197, -0.09014118, -0.17435393, -0.19562316,  0.6061667 ,\n",
      "        -0.51854086,  0.6417493 ],\n",
      "       [-0.24103452,  0.57592934, -0.54418564, -0.02312291, -0.5350481 ,\n",
      "        -0.4740319 ,  0.4938487 ]], dtype=float32)>, <tf.Variable 'dense_10/bias:0' shape=(7,) dtype=float32, numpy=\n",
      "array([ 0.1574476 ,  0.0008621 , -0.01388858,  0.15134063,  0.29616374,\n",
      "        0.12738383, -0.12433388], dtype=float32)>]\n",
      "[<tf.Variable 'dense_11/kernel:0' shape=(7, 1) dtype=float32, numpy=\n",
      "array([[ 0.6135964 ],\n",
      "       [ 0.65261036],\n",
      "       [-0.8290646 ],\n",
      "       [ 0.03483403],\n",
      "       [ 0.15617305],\n",
      "       [ 0.32371703],\n",
      "       [ 0.0703434 ]], dtype=float32)>, <tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([-0.04701389], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weights)\n",
    "print(model.layers[1].weights)\n",
    "print(model.layers[2].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIzaAMqsJtvJ",
    "outputId": "32a9181a-d2bc-47af-e515-f29a520917fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9698907 ],\n",
       "       [0.73424274],\n",
       "       [0.5431979 ],\n",
       "       [0.9662256 ],\n",
       "       [0.5602138 ],\n",
       "       [0.62263054],\n",
       "       [0.81268394],\n",
       "       [0.5875509 ],\n",
       "       [0.5255271 ],\n",
       "       [0.6335877 ],\n",
       "       [0.66758823],\n",
       "       [0.5966896 ],\n",
       "       [0.52227205],\n",
       "       [0.7233653 ],\n",
       "       [0.5391646 ],\n",
       "       [0.69971335],\n",
       "       [0.5274507 ],\n",
       "       [0.6323637 ],\n",
       "       [0.77164006],\n",
       "       [0.9109055 ],\n",
       "       [0.8736655 ],\n",
       "       [0.8023613 ],\n",
       "       [0.6856189 ],\n",
       "       [0.49334657],\n",
       "       [0.78055567],\n",
       "       [0.91007733],\n",
       "       [0.7405379 ],\n",
       "       [0.7064354 ],\n",
       "       [0.575803  ],\n",
       "       [0.65606534],\n",
       "       [0.73169565],\n",
       "       [0.98439324],\n",
       "       [0.54850394],\n",
       "       [0.9648322 ],\n",
       "       [0.691336  ],\n",
       "       [0.72030896],\n",
       "       [0.82939994],\n",
       "       [0.8160341 ],\n",
       "       [0.6738607 ],\n",
       "       [0.6822252 ],\n",
       "       [0.8359501 ],\n",
       "       [0.97100174],\n",
       "       [0.8423277 ],\n",
       "       [0.9366146 ],\n",
       "       [0.580405  ],\n",
       "       [0.7835609 ],\n",
       "       [0.76377606],\n",
       "       [1.0121633 ],\n",
       "       [0.886088  ],\n",
       "       [0.78782415],\n",
       "       [0.63568735],\n",
       "       [0.55050355],\n",
       "       [0.94382584],\n",
       "       [0.6882522 ],\n",
       "       [0.7406305 ],\n",
       "       [0.5900795 ],\n",
       "       [0.93472165],\n",
       "       [0.7424066 ],\n",
       "       [1.0009599 ],\n",
       "       [0.7521037 ],\n",
       "       [0.57694554],\n",
       "       [0.7618203 ],\n",
       "       [0.6982217 ],\n",
       "       [0.93946517],\n",
       "       [0.70569944],\n",
       "       [0.68958235],\n",
       "       [0.71294224],\n",
       "       [0.79326665],\n",
       "       [0.6936606 ],\n",
       "       [0.75099725],\n",
       "       [0.65713394],\n",
       "       [0.5899751 ],\n",
       "       [0.6339862 ],\n",
       "       [0.90361166],\n",
       "       [0.844494  ],\n",
       "       [0.8902637 ],\n",
       "       [0.87953866],\n",
       "       [0.66245466],\n",
       "       [0.49730146],\n",
       "       [0.6075189 ],\n",
       "       [0.6080953 ],\n",
       "       [0.7857851 ],\n",
       "       [0.5580017 ],\n",
       "       [0.86424005],\n",
       "       [0.97079337],\n",
       "       [0.6184085 ],\n",
       "       [0.7618866 ],\n",
       "       [0.79696846],\n",
       "       [0.5647065 ],\n",
       "       [0.8421682 ],\n",
       "       [0.6602944 ],\n",
       "       [0.9881619 ],\n",
       "       [0.88199455],\n",
       "       [0.7064337 ],\n",
       "       [0.7570433 ],\n",
       "       [0.6323629 ],\n",
       "       [0.4431926 ],\n",
       "       [0.838705  ],\n",
       "       [0.8143711 ],\n",
       "       [0.6710265 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test_trf)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Npb6XINLMA6T",
    "outputId": "f14de4fd-7467-427f-80e8-e8fc9eddd9a6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMlDU06xMjHi",
    "outputId": "8d7e03e6-2ca8-4806-be81-12b8e7e6d9fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7715583971765312"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "tIQakIYrMxKa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3939414620399475,\n",
       "  0.029896652325987816,\n",
       "  0.018166132271289825,\n",
       "  0.014508256688714027,\n",
       "  0.01215380523353815,\n",
       "  0.009280805476009846,\n",
       "  0.008121143095195293,\n",
       "  0.00676193879917264,\n",
       "  0.006028462201356888,\n",
       "  0.00549327302724123,\n",
       "  0.0052726478315889835,\n",
       "  0.005299463868141174,\n",
       "  0.004767534323036671,\n",
       "  0.004615297075361013,\n",
       "  0.004491076339036226,\n",
       "  0.004439071752130985,\n",
       "  0.004312367644160986,\n",
       "  0.004040224011987448,\n",
       "  0.004065075423568487,\n",
       "  0.004029081668704748,\n",
       "  0.003960158675909042,\n",
       "  0.0039384691044688225,\n",
       "  0.003990469966083765,\n",
       "  0.0037912458647042513,\n",
       "  0.003794083371758461,\n",
       "  0.0038092341274023056,\n",
       "  0.0037301371339708567,\n",
       "  0.0037134671583771706,\n",
       "  0.0037017944268882275,\n",
       "  0.003773486940190196,\n",
       "  0.0037019255105406046,\n",
       "  0.0037378070410341024,\n",
       "  0.003641726914793253,\n",
       "  0.0037073532585054636,\n",
       "  0.003672391874715686,\n",
       "  0.0036596653517335653,\n",
       "  0.003680943278595805,\n",
       "  0.003632924286648631,\n",
       "  0.0035663836169987917,\n",
       "  0.00373598700389266,\n",
       "  0.003641954157501459,\n",
       "  0.003599780611693859,\n",
       "  0.0035989030729979277,\n",
       "  0.0036944185849279165,\n",
       "  0.003641626564785838,\n",
       "  0.003486417466774583,\n",
       "  0.003810016205534339,\n",
       "  0.0035249183420091867,\n",
       "  0.003558517899364233,\n",
       "  0.003514622338116169,\n",
       "  0.0035200812853872776,\n",
       "  0.00353928841650486,\n",
       "  0.0034594323951750994,\n",
       "  0.0036522643640637398,\n",
       "  0.00345248868688941,\n",
       "  0.003514160867780447,\n",
       "  0.0034721812698990107,\n",
       "  0.003492287127301097,\n",
       "  0.0034561443608254194,\n",
       "  0.003418765729293227,\n",
       "  0.0034220474772155285,\n",
       "  0.0035592943895608187,\n",
       "  0.0034346249885857105,\n",
       "  0.003596582217141986,\n",
       "  0.0034597311168909073,\n",
       "  0.003423280082643032,\n",
       "  0.003548294072970748,\n",
       "  0.003488394897431135,\n",
       "  0.003613659180700779,\n",
       "  0.0034433084074407816,\n",
       "  0.0037468194495886564,\n",
       "  0.003453505225479603,\n",
       "  0.0034140851348638535,\n",
       "  0.003375172847881913,\n",
       "  0.0034423875622451305,\n",
       "  0.0034882088657468557,\n",
       "  0.0035852862056344748,\n",
       "  0.003389612538740039,\n",
       "  0.00339290639385581,\n",
       "  0.003435262478888035,\n",
       "  0.0033454594668000937,\n",
       "  0.0034985970705747604,\n",
       "  0.003431272692978382,\n",
       "  0.0035265011247247458,\n",
       "  0.0033989972434937954,\n",
       "  0.003449804149568081,\n",
       "  0.003399940673261881,\n",
       "  0.0035649423953145742,\n",
       "  0.0034361842554062605,\n",
       "  0.0033595270942896605,\n",
       "  0.0033804159611463547,\n",
       "  0.0034257525112479925,\n",
       "  0.003412791760638356,\n",
       "  0.0032992803025990725,\n",
       "  0.003455724334344268,\n",
       "  0.003446429269388318,\n",
       "  0.0034816842526197433,\n",
       "  0.0034065258223563433,\n",
       "  0.0035510666202753782,\n",
       "  0.003353874431923032]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIwPgwFIQA24",
    "outputId": "a17b65b8-f1a4-4e35-c4ad-8cb544a7d8fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIxqtaAuQUL3",
    "outputId": "3e50b33b-a707-4802-e7e7-166bc2c73ea5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMfTo_O_SJkT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lab2_churn_predection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
