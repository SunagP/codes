{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EgiKfwVqDZjX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oT_Fu9jiDr64"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Predict_Ver.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c1YTCsooD4Nb",
    "outputId": "a58ee380-199b-46c2-bfac-b7accf071875"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQeAorrzE8gg",
    "outputId": "89aabcc4-6f83-4db8-9830-687f4f446385"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore  Geography  Gender  Age  Tenure  Balance    NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited\n",
       "350          France     Female  40   0       111098.85  1              1          1               172321.21        1         1\n",
       "695          France     Male    36   4       161533.00  1              1          0               100940.91        0         1\n",
       "                        Female  36   2       0.00       2              0          1               167749.54        0         1\n",
       "                                42   0       0.00       2              0          1               140724.64        0         1\n",
       "                                     5       0.00       1              0          1               72172.13         1         1\n",
       "                                                                                                                            ..\n",
       "608          France     Male    42   5       0.00       2              1          0               178504.29        0         1\n",
       "                                     10      163548.07  1              1          0               38866.85         0         1\n",
       "                                50   6       0.00       1              1          0               93568.77         1         1\n",
       "                                59   1       0.00       1              1          0               70649.64         1         1\n",
       "850          Spain      Male    71   10      69608.14   1              1          0               97893.40         1         1\n",
       "Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXLVutEeFEEe",
    "outputId": "99360f86-24ee-488a-f0f7-a904b811b1ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geography'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "id": "L5M8M5YIFLjm",
    "outputId": "e3822b79-0235-4177-84b8-d61c6835bf44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7fcda795-f9a3-4e6c-8b6b-59eaa67ca94f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fcda795-f9a3-4e6c-8b6b-59eaa67ca94f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7fcda795-f9a3-4e6c-8b6b-59eaa67ca94f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7fcda795-f9a3-4e6c-8b6b-59eaa67ca94f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df,columns=['Geography','Gender'],drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFdyqWWRF52Y"
   },
   "outputs": [],
   "source": [
    "x=df.drop(columns=['Exited'])\n",
    "y=df['Exited'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dqmw9W4sGopf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lT_2UWZfG9Wv"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar=StandardScaler()\n",
    "\n",
    "x_tranin_trf=scalar.fit_transform(x_train)\n",
    "x_test_trf=scalar.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHyayYPWHWKK"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uk-0bdEZIjpI",
    "outputId": "ff9d1a05-42cb-4129-ec81-10814cb482f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 3)                 36        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tensorflow.keras.Sequential()\n",
    "model.add(Dense(3,activation='sigmoid',input_dim=11))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpSaldb0KHt2",
    "outputId": "f1f80d6b-7cfb-45a7-a69c-964e522829b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5826\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7933\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7933\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7933\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7933\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7933\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7933\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7933\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7933\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7933\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7933\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7933\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7933\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7933\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7933\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7933\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7933\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7933\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7933\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7933\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7933\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7933\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7933\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7933\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7933\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7933\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7933\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7933\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "history=model.fit(x_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UraOpGqJW3B",
    "outputId": "44dc5f6d-0081-430d-91c0-c69f4668106a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3=tensorflow.keras.Sequential()\n",
    "model3.add(Dense(11,activation='sigmoid',input_dim=11))\n",
    "model3.add(Dense(11,activation='sigmoid'))\n",
    "model3.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIzaAMqsJtvJ",
    "outputId": "32a9181a-d2bc-47af-e515-f29a520917fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.8115 - accuracy: 0.4467\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7933\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7933\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7933\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7933\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7933\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7933\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7933\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7933\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7933\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7933\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7933\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7933\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7933\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7933\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7933\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7933\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7933\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7933\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7933\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7933\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7933\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7933\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7933\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7933\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7933\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7933\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7933\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7933\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7933\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7933\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7933\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7933\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7933\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7933\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7933\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7933\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7933\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7933\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7933\n"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer='Adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "history=model3.fit(x_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Npb6XINLMA6T",
    "outputId": "f14de4fd-7467-427f-80e8-e8fc9eddd9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.7933\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4527 - accuracy: 0.7955\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8049\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8074\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8077\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8085\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8087\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8100\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8094\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8130\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8130\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8155\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8185\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8196\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8209\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8220\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8248\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8265\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8292\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8289\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8317\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8306\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8340\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8342\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8346\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8356\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8349\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8370\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8349\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8366\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8360\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8370\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8361\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8363\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8365\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8370\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8375\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8375\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8369\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8371\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8366\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8369\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8379\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8380\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8370\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8359\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8384\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8386\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8375\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8381\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "history=model.fit(x_tranin_trf,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMlDU06xMjHi",
    "outputId": "8d7e03e6-2ca8-4806-be81-12b8e7e6d9fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18473244],\n",
       "       [0.02516329],\n",
       "       [0.5751702 ],\n",
       "       ...,\n",
       "       [0.5751702 ],\n",
       "       [0.5751702 ],\n",
       "       [0.02516329]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIQakIYrMxKa"
   },
   "outputs": [],
   "source": [
    "y_pred=y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIwPgwFIQA24",
    "outputId": "a17b65b8-f1a4-4e35-c4ad-8cb544a7d8fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4=tensorflow.keras.Sequential()\n",
    "model4.add(Dense(11,activation='relu',input_dim=11))\n",
    "model4.add(Dense(11,activation='relu'))\n",
    "model4.add(Dense(1,activation='relu'))\n",
    "\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIxqtaAuQUL3",
    "outputId": "3e50b33b-a707-4802-e7e7-166bc2c73ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 3.1891 - accuracy: 0.7933\n"
     ]
    }
   ],
   "source": [
    "model4.compile(optimizer='Adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "history=model4.fit(x_train,y_train,epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMfTo_O_SJkT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lab2_churn_predection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
