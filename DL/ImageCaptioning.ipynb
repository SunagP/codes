{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:01.681838Z",
     "iopub.status.busy": "2022-06-25T11:16:01.681295Z",
     "iopub.status.idle": "2022-06-25T11:16:03.900992Z",
     "shell.execute_reply": "2022-06-25T11:16:03.899785Z",
     "shell.execute_reply.started": "2022-06-25T11:16:01.681805Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:03.903579Z",
     "iopub.status.busy": "2022-06-25T11:16:03.902846Z",
     "iopub.status.idle": "2022-06-25T11:16:03.910441Z",
     "shell.execute_reply": "2022-06-25T11:16:03.909335Z",
     "shell.execute_reply.started": "2022-06-25T11:16:03.903534Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:03.912546Z",
     "iopub.status.busy": "2022-06-25T11:16:03.912087Z",
     "iopub.status.idle": "2022-06-25T11:16:03.921401Z",
     "shell.execute_reply": "2022-06-25T11:16:03.92052Z",
     "shell.execute_reply.started": "2022-06-25T11:16:03.912501Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:03.925383Z",
     "iopub.status.busy": "2022-06-25T11:16:03.924944Z",
     "iopub.status.idle": "2022-06-25T11:16:06.361671Z",
     "shell.execute_reply": "2022-06-25T11:16:06.360458Z",
     "shell.execute_reply.started": "2022-06-25T11:16:03.92535Z"
    }
   },
   "outputs": [],
   "source": [
    "model=VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:06.363424Z",
     "iopub.status.busy": "2022-06-25T11:16:06.363108Z",
     "iopub.status.idle": "2022-06-25T11:16:06.373619Z",
     "shell.execute_reply": "2022-06-25T11:16:06.372463Z",
     "shell.execute_reply.started": "2022-06-25T11:16:06.363395Z"
    }
   },
   "outputs": [],
   "source": [
    "model=Model(inputs=model.inputs,outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:06.375495Z",
     "iopub.status.busy": "2022-06-25T11:16:06.375117Z",
     "iopub.status.idle": "2022-06-25T11:16:06.400943Z",
     "shell.execute_reply": "2022-06-25T11:16:06.399476Z",
     "shell.execute_reply.started": "2022-06-25T11:16:06.375411Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:06.402935Z",
     "iopub.status.busy": "2022-06-25T11:16:06.402613Z",
     "iopub.status.idle": "2022-06-25T11:16:06.413936Z",
     "shell.execute_reply": "2022-06-25T11:16:06.413013Z",
     "shell.execute_reply.started": "2022-06-25T11:16:06.402905Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR='/kaggle/input/flickr8k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:06.416939Z",
     "iopub.status.busy": "2022-06-25T11:16:06.415971Z",
     "iopub.status.idle": "2022-06-25T11:16:06.425608Z",
     "shell.execute_reply": "2022-06-25T11:16:06.424526Z",
     "shell.execute_reply.started": "2022-06-25T11:16:06.416892Z"
    }
   },
   "outputs": [],
   "source": [
    "features={}\n",
    "directory=os.path.join(BASE_DIR,'Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:16:06.429068Z",
     "iopub.status.busy": "2022-06-25T11:16:06.428674Z",
     "iopub.status.idle": "2022-06-25T12:05:01.5648Z",
     "shell.execute_reply": "2022-06-25T12:05:01.563862Z",
     "shell.execute_reply.started": "2022-06-25T11:16:06.429026Z"
    }
   },
   "outputs": [],
   "source": [
    "for img_name in tqdm(os.listdir(directory)):\n",
    "    img_path=directory+'/'+img_name\n",
    "    img=load_img(img_path,target_size=(224,224))\n",
    "    img=img_to_array(img)\n",
    "    img=img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    img=preprocess_input(img)\n",
    "    feature=model.predict(img,verbose=0)\n",
    "    img_id = img_name.split('.')[0]\n",
    "    features[img_id]=feature\n",
    "    \n",
    "#     print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:01.566365Z",
     "iopub.status.busy": "2022-06-25T12:05:01.565889Z",
     "iopub.status.idle": "2022-06-25T12:05:02.016023Z",
     "shell.execute_reply": "2022-06-25T12:05:02.014862Z",
     "shell.execute_reply.started": "2022-06-25T12:05:01.566335Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(features, open(os.path.join('', 'features.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.018029Z",
     "iopub.status.busy": "2022-06-25T12:05:02.017595Z",
     "iopub.status.idle": "2022-06-25T12:05:02.096874Z",
     "shell.execute_reply": "2022-06-25T12:05:02.09559Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.017988Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_DIR, 'captions.txt'), 'r') as f:\n",
    "    next(f)\n",
    "    captions_doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.09836Z",
     "iopub.status.busy": "2022-06-25T12:05:02.098056Z",
     "iopub.status.idle": "2022-06-25T12:05:02.18229Z",
     "shell.execute_reply": "2022-06-25T12:05:02.180979Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.098333Z"
    }
   },
   "outputs": [],
   "source": [
    "captions_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.185156Z",
     "iopub.status.busy": "2022-06-25T12:05:02.183971Z",
     "iopub.status.idle": "2022-06-25T12:05:02.34442Z",
     "shell.execute_reply": "2022-06-25T12:05:02.343273Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.185119Z"
    }
   },
   "outputs": [],
   "source": [
    "mapp={}\n",
    "c=1\n",
    "for lines in tqdm(captions_doc.split('\\n')):\n",
    "    captions=lines.split(',')\n",
    "\n",
    "    if len(lines)<2:\n",
    "        continue\n",
    "    img_id,caption=captions[0],captions[1:]\n",
    "    img_id=img_id.split('.')[0]\n",
    "    caption = \" \".join(caption)\n",
    "    if img_id not in mapp :\n",
    "        mapp[img_id]=[]\n",
    "    mapp[img_id].append(caption)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.347773Z",
     "iopub.status.busy": "2022-06-25T12:05:02.345834Z",
     "iopub.status.idle": "2022-06-25T12:05:02.524979Z",
     "shell.execute_reply": "2022-06-25T12:05:02.523797Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.347728Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, captions in mapp.items():\n",
    "    for i in range(len(captions)):\n",
    "        # take one caption at a time\n",
    "        caption = captions[i]\n",
    "        # preprocessing steps\n",
    "        # convert to lowercase\n",
    "        caption = caption.lower()\n",
    "        # delete digits, special chars, etc., \n",
    "        caption = caption.replace('[^A-Za-z]', '')\n",
    "        # delete additional spaces\n",
    "        caption = caption.replace('\\s+', ' ')\n",
    "        # add start and end tags to the caption\n",
    "        caption = 'startseq ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq'\n",
    "        captions[i] = caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.527026Z",
     "iopub.status.busy": "2022-06-25T12:05:02.526659Z",
     "iopub.status.idle": "2022-06-25T12:05:02.532312Z",
     "shell.execute_reply": "2022-06-25T12:05:02.531609Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.526994Z"
    }
   },
   "outputs": [],
   "source": [
    "mapp['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.534069Z",
     "iopub.status.busy": "2022-06-25T12:05:02.533776Z",
     "iopub.status.idle": "2022-06-25T12:05:02.555778Z",
     "shell.execute_reply": "2022-06-25T12:05:02.554916Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.534043Z"
    }
   },
   "outputs": [],
   "source": [
    "all_cap=[]\n",
    "for i in mapp:\n",
    "    for cap in mapp[i]:\n",
    "        all_cap.append(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.557703Z",
     "iopub.status.busy": "2022-06-25T12:05:02.556945Z",
     "iopub.status.idle": "2022-06-25T12:05:02.57036Z",
     "shell.execute_reply": "2022-06-25T12:05:02.569641Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.557661Z"
    }
   },
   "outputs": [],
   "source": [
    "len(all_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.572571Z",
     "iopub.status.busy": "2022-06-25T12:05:02.572103Z",
     "iopub.status.idle": "2022-06-25T12:05:02.58101Z",
     "shell.execute_reply": "2022-06-25T12:05:02.580113Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.572523Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:02.582943Z",
     "iopub.status.busy": "2022-06-25T12:05:02.582407Z",
     "iopub.status.idle": "2022-06-25T12:05:03.304737Z",
     "shell.execute_reply": "2022-06-25T12:05:03.303594Z",
     "shell.execute_reply.started": "2022-06-25T12:05:02.582901Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.310508Z",
     "iopub.status.busy": "2022-06-25T12:05:03.309853Z",
     "iopub.status.idle": "2022-06-25T12:05:03.351011Z",
     "shell.execute_reply": "2022-06-25T12:05:03.349826Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.310448Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.352914Z",
     "iopub.status.busy": "2022-06-25T12:05:03.352593Z",
     "iopub.status.idle": "2022-06-25T12:05:03.357398Z",
     "shell.execute_reply": "2022-06-25T12:05:03.35663Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.352885Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.359336Z",
     "iopub.status.busy": "2022-06-25T12:05:03.358635Z",
     "iopub.status.idle": "2022-06-25T12:05:03.403676Z",
     "shell.execute_reply": "2022-06-25T12:05:03.402308Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.359303Z"
    }
   },
   "outputs": [],
   "source": [
    "max_word_len=max(len(captions.split()) for captions in all_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.405569Z",
     "iopub.status.busy": "2022-06-25T12:05:03.405213Z",
     "iopub.status.idle": "2022-06-25T12:05:03.411763Z",
     "shell.execute_reply": "2022-06-25T12:05:03.410592Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.405538Z"
    }
   },
   "outputs": [],
   "source": [
    "max_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.413958Z",
     "iopub.status.busy": "2022-06-25T12:05:03.413363Z",
     "iopub.status.idle": "2022-06-25T12:05:03.423074Z",
     "shell.execute_reply": "2022-06-25T12:05:03.421885Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.413923Z"
    }
   },
   "outputs": [],
   "source": [
    "image_ids = list(mapp.keys())\n",
    "split_index=int(len(list(mapp.keys()))*0.90)\n",
    "\n",
    "train=image_ids[:split_index]\n",
    "test=image_ids[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.42521Z",
     "iopub.status.busy": "2022-06-25T12:05:03.424574Z",
     "iopub.status.idle": "2022-06-25T12:05:03.439078Z",
     "shell.execute_reply": "2022-06-25T12:05:03.437836Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.425172Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.441217Z",
     "iopub.status.busy": "2022-06-25T12:05:03.440655Z",
     "iopub.status.idle": "2022-06-25T12:05:03.450561Z",
     "shell.execute_reply": "2022-06-25T12:05:03.449792Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.441172Z"
    }
   },
   "outputs": [],
   "source": [
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.452243Z",
     "iopub.status.busy": "2022-06-25T12:05:03.451657Z",
     "iopub.status.idle": "2022-06-25T12:05:03.461365Z",
     "shell.execute_reply": "2022-06-25T12:05:03.460482Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.452207Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.463378Z",
     "iopub.status.busy": "2022-06-25T12:05:03.462861Z",
     "iopub.status.idle": "2022-06-25T12:05:03.478224Z",
     "shell.execute_reply": "2022-06-25T12:05:03.477315Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.463343Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
    "    # loop over images\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    while 1:\n",
    "        for key in data_keys:\n",
    "            n += 1\n",
    "            captions = mapping[key]\n",
    "            # process each caption\n",
    "            for caption in captions:\n",
    "                # encode the sequence\n",
    "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "                # split the sequence into X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pairs\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    \n",
    "                    # store the sequences\n",
    "                    X1.append(features[key][0])\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            if n == batch_size:\n",
    "                X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                yield [X1, X2], y\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:03.480587Z",
     "iopub.status.busy": "2022-06-25T12:05:03.479699Z",
     "iopub.status.idle": "2022-06-25T12:05:05.72763Z",
     "shell.execute_reply": "2022-06-25T12:05:05.726214Z",
     "shell.execute_reply.started": "2022-06-25T12:05:03.480553Z"
    }
   },
   "outputs": [],
   "source": [
    "input1=Input(shape=(4096,))\n",
    "fe1 = Dropout(0.3)(input1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "\n",
    "inputs2 = Input(shape=(max_word_len,))\n",
    "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.4)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "\n",
    "\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "model = Model(inputs=[input1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T12:05:05.730424Z",
     "iopub.status.busy": "2022-06-25T12:05:05.729925Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "steps = len(train) // batch_size\n",
    "\n",
    "for i in range(epochs):\n",
    "    # create data generator\n",
    "    generator = data_generator(train, mapp, features, tokenizer, max_word_len, vocab_size, batch_size)\n",
    "    # fit for one epoch\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T10:58:04.690676Z",
     "iopub.status.busy": "2022-06-25T10:58:04.690235Z",
     "iopub.status.idle": "2022-06-25T10:58:04.700508Z",
     "shell.execute_reply": "2022-06-25T10:58:04.699403Z",
     "shell.execute_reply.started": "2022-06-25T10:58:04.690643Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, features, hidden):\n",
    "    # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
    "\n",
    "    # hidden shape == (batch_size, hidden_size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
    "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "    # attention_hidden_layer shape == (batch_size, 64, units)\n",
    "    attention_hidden_layer = (tf.nn.tanh(self.W1(features) +\n",
    "                                         self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # score shape == (batch_size, 64, 1)\n",
    "    # This gives you an unnormalized score for each image feature.\n",
    "    score = self.V(attention_hidden_layer)\n",
    "\n",
    "    # attention_weights shape == (batch_size, 64, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * features\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T10:58:28.002388Z",
     "iopub.status.busy": "2022-06-25T10:58:28.001756Z",
     "iopub.status.idle": "2022-06-25T10:58:28.013021Z",
     "shell.execute_reply": "2022-06-25T10:58:28.011035Z",
     "shell.execute_reply.started": "2022-06-25T10:58:28.002332Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CNN_Encoder(tf.keras.Model):\n",
    "    # Since you have already extracted the features and dumped it\n",
    "    # This encoder passes those features through a Fully connected layer\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        # shape after fc == (batch_size, 64, embedding_dim)\n",
    "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T10:58:43.985831Z",
     "iopub.status.busy": "2022-06-25T10:58:43.985409Z",
     "iopub.status.idle": "2022-06-25T10:58:44.001174Z",
     "shell.execute_reply": "2022-06-25T10:58:43.999968Z",
     "shell.execute_reply.started": "2022-06-25T10:58:43.985787Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "  def __init__(self, embedding_dim, units, vocab_size):\n",
    "    super(RNN_Decoder, self).__init__()\n",
    "    self.units = units\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc1 = tf.keras.layers.Dense(self.units)\n",
    "    self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "  def call(self, x, features, hidden):\n",
    "    # defining attention as a separate model\n",
    "    context_vector, attention_weights = self.attention(features, hidden)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # shape == (batch_size, max_length, hidden_size)\n",
    "    x = self.fc1(output)\n",
    "\n",
    "    # x shape == (batch_size * max_length, hidden_size)\n",
    "    x = tf.reshape(x, (-1, x.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size * max_length, vocab)\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return x, state, attention_weights\n",
    "\n",
    "  def reset_state(self, batch_size):\n",
    "    return tf.zeros((batch_size, self.units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:01:02.922334Z",
     "iopub.status.busy": "2022-06-25T11:01:02.921297Z",
     "iopub.status.idle": "2022-06-25T11:01:02.928749Z",
     "shell.execute_reply": "2022-06-25T11:01:02.927358Z",
     "shell.execute_reply.started": "2022-06-25T11:01:02.922287Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "num_steps = len(train) // BATCH_SIZE\n",
    "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
    "# These two variables represent that vector shape\n",
    "features_shape = 2048\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:03:26.565831Z",
     "iopub.status.busy": "2022-06-25T11:03:26.565405Z",
     "iopub.status.idle": "2022-06-25T11:03:26.606244Z",
     "shell.execute_reply": "2022-06-25T11:03:26.604672Z",
     "shell.execute_reply.started": "2022-06-25T11:03:26.5658Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:02:04.330991Z",
     "iopub.status.busy": "2022-06-25T11:02:04.330563Z",
     "iopub.status.idle": "2022-06-25T11:02:04.339133Z",
     "shell.execute_reply": "2022-06-25T11:02:04.338197Z",
     "shell.execute_reply.started": "2022-06-25T11:02:04.330961Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:03:32.251263Z",
     "iopub.status.busy": "2022-06-25T11:03:32.2505Z",
     "iopub.status.idle": "2022-06-25T11:03:32.267121Z",
     "shell.execute_reply": "2022-06-25T11:03:32.265493Z",
     "shell.execute_reply.started": "2022-06-25T11:03:32.251198Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:03:51.551289Z",
     "iopub.status.busy": "2022-06-25T11:03:51.550895Z",
     "iopub.status.idle": "2022-06-25T11:03:51.55727Z",
     "shell.execute_reply": "2022-06-25T11:03:51.556192Z",
     "shell.execute_reply.started": "2022-06-25T11:03:51.551258Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "  # restoring the latest checkpoint in checkpoint_path\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:07:24.631941Z",
     "iopub.status.busy": "2022-06-25T11:07:24.631334Z",
     "iopub.status.idle": "2022-06-25T11:07:24.64099Z",
     "shell.execute_reply": "2022-06-25T11:07:24.639447Z",
     "shell.execute_reply.started": "2022-06-25T11:07:24.631883Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "loss_plot = []\n",
    "batch_size=32\n",
    "generator = data_generator(train, mapp, features, tokenizer, max_word_len, vocab_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:07:34.031485Z",
     "iopub.status.busy": "2022-06-25T11:07:34.031063Z",
     "iopub.status.idle": "2022-06-25T11:07:34.040265Z",
     "shell.execute_reply": "2022-06-25T11:07:34.038587Z",
     "shell.execute_reply.started": "2022-06-25T11:07:34.031454Z"
    }
   },
   "outputs": [],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T11:04:24.010968Z",
     "iopub.status.busy": "2022-06-25T11:04:24.010526Z",
     "iopub.status.idle": "2022-06-25T11:04:24.022309Z",
     "shell.execute_reply": "2022-06-25T11:04:24.02093Z",
     "shell.execute_reply.started": "2022-06-25T11:04:24.010936Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img_tensor, target):\n",
    "  loss = 0\n",
    "\n",
    "  # initializing the hidden state for each batch\n",
    "  # because the captions are not related from image to image\n",
    "  hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "\n",
    "  dec_input = tf.expand_dims([word_to_index('<start>')] * target.shape[0], 1)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "      features = encoder(img_tensor)\n",
    "\n",
    "      for i in range(1, target.shape[1]):\n",
    "          # passing the features through the decoder\n",
    "          predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "\n",
    "          loss += loss_function(target[:, i], predictions)\n",
    "\n",
    "          # using teacher forcing\n",
    "          dec_input = tf.expand_dims(target[:, i], 1)\n",
    "\n",
    "  total_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "  return loss, total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            average_batch_loss = batch_loss.numpy()/int(target.shape[1])\n",
    "            print(f'Epoch {epoch+1} Batch {batch} Loss {average_batch_loss:.4f}')\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "      ckpt_manager.save()\n",
    "\n",
    "    print(f'Epoch {epoch+1} Loss {total_loss/num_steps:.6f}')\n",
    "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
